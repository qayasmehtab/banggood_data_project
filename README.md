ğŸ“¦ Banggood Product Data Pipeline & Analysis

A complete end-to-end data pipeline for scraping, cleaning, analyzing, and visualizing product data from Banggood.com.

This project covers everything from web scraping â†’ cleaning â†’ EDA â†’ SQL storage â†’ dashboard visualization built using Python, Pandas, Matplotlib, Seaborn, SQLite, and Streamlit.

 Project Overview

This pipeline automates a full data workflow:

1. Web Scraping

Scrapes product data from 5 Banggood categories

Captures:

Product Name

Price

Rating

Reviews

Product URL

2. Data Cleaning

Handles missing values

Converts data types

Cleans prices & ratings

Removes duplicates

3. Exploratory Data Analysis (EDA)

Top-rated products
<img width="1024" height="1536" alt="- Architecture Diagram" src="https://github.com/user-attachments/assets/3bf98313-db1c-487d-b708-70dc0114df4c" />
<img width="1024" height="1536" alt="- Architecture Diagram" src="https://github.com/user-attachments/assets/6853638c-76d1-42d4-8b11-2e9f7adadc57" />
![Uploading Architecture Diagram.pngâ€¦]()

Most expensive & cheapest products

Pricing distribution

Category insights (ratings, reviews, etc.)

 4. SQL Pipeline

Stores clean data in SQLite

Creates category-wise tables

Performs SQL aggregation queries

 5. Dashboard (Streamlit)

Interactive product analysis

Bar charts, histograms, category comparisons

Priceâ€“rating insights

ğŸ“ Project Structure
Banggood_Project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ clean/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ banggood_scraper.py
â”‚   â”œâ”€â”€ cleaning.py
â”‚   â”œâ”€â”€ eda.py
â”‚   â”œâ”€â”€ to_sql.py
â”‚   â””â”€â”€ dashboard.py
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ architecture_diagram.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py

ğŸ› ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/YourUsername/Banggood_Project.git
cd Banggood_Project

2ï¸âƒ£ Create Virtual Environment
python -m venv venv

3ï¸âƒ£ Activate Virtual Environment

Windows:

venv\Scripts\activate

source venv/bin/activate

4ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

â–¶ï¸ How to Run the Project
ğŸ•¸ï¸ Run the Scraper
python scripts/banggood_scraper.py

ğŸ§¼ Clean the Data
python scripts/cleaning.py

ğŸ“Š Run EDA
python scripts/eda.py

ğŸ—„ï¸ Store in SQL
python scripts/to_sql.py

ğŸ“ˆ Launch Dashboard
streamlit run scripts/dashboard.py

ğŸ“¸ Architecture Diagram

A high-level overview of the full pipeline.

(Add your architecture diagram here)

ğŸ¤ Contributing

Pull requests and suggestions are welcome!
Feel free to open an issue or submit improvements.

â­ If You Like This Project

Donâ€™t forget to Star â­ the repository on GitHub!
Your support motivates continuous improvement.

ğŸ‘¨â€ğŸ’» Author

Qayas Abbasi
Cloud Data Engineer | Python Developer | Data Pipeline Enthusiast


